{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exloring the movie review data\n",
    "In separate sheet to keep sheets running the models from being too cluttered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jeremie/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory exists, taking no action\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wget\n",
    "import tarfile\n",
    "\n",
    "# By checking if the directory exists first, we allow people to delete the tarfile without the notebook re-downloading it\n",
    "if os.path.isdir('aclImdb'):\n",
    "    print(\"Dataset directory exists, taking no action\")\n",
    "else:    \n",
    "    if not os.path.isfile('aclImdb_v1.tar.gz'):\n",
    "        print(\"Downloading dataset\")\n",
    "        #!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "        wget.download('http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz')\n",
    "    else:\n",
    "        print(\"Dataset already downloaded\")\n",
    "    \n",
    "    print(\"Unpacking dataset\")\n",
    "    #!tar -xf aclImdb_v1.tar.gz \n",
    "    tar = tarfile.open(\"aclImdb_v1.tar.gz\")\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "    print(\"Dataset unpacked in aclImdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "SAMPLE_SIZE=1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_beginning_of_notebook = time.time()\n",
    "positive_file_list = glob.glob(os.path.join('aclImdb/train/pos', \"*.txt\"))\n",
    "positive_sample_file_list = positive_file_list[:SAMPLE_SIZE]\n",
    "\n",
    "negative_file_list = glob.glob(os.path.join('aclImdb/train/neg', \"*.txt\"))\n",
    "negative_sample_file_list = negative_file_list[:SAMPLE_SIZE]\n",
    "\n",
    "import re\n",
    "\n",
    "# load doc into memory\n",
    "# regex to clean markup elements \n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r', encoding='utf8')\n",
    "    # read all text\n",
    "    text = re.sub('<[^>]*>', ' ', file.read())\n",
    "    #text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_strings = [load_doc(x) for x in positive_sample_file_list]\n",
    "negative_strings = [load_doc(x) for x in negative_sample_file_list]\n",
    "\n",
    "positive_tokenized = [word_tokenize(s) for s in positive_strings]\n",
    "negative_tokenized = [word_tokenize(s) for s in negative_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_positive_and_negative(i):\n",
    "    print(positive_strings[i][:30] + \"\\t:\\t\" + negative_strings[i][:30] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "\n",
      " Positive reviews \n",
      "  I thought I should qualify my position after readi\n",
      "\n",
      " Negative reviews \n",
      "  I feel totally ripped off. Someone needs to refund\n"
     ]
    }
   ],
   "source": [
    "print(len(positive_strings) + len(negative_strings))\n",
    "print('\\n Positive reviews \\n ', positive_strings[0][:50])\n",
    "print('\\n Negative reviews \\n ', negative_strings[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive reviews \t : \t negative reviews\n",
      "\n",
      "I thought I should qualify my \t:\tI feel totally ripped off. Som...\n",
      "In the same vein as Natural Bo\t:\tThe makers of this film have c...\n",
      "Airwolf The Movie, A variation\t:\t**SPOILERS** I rented \"Tesis\" ...\n",
      "Revenge is the theme of this D\t:\tthis, is NOT one of those film...\n",
      "\"A Girl's Folly\" is a sort of \t:\tThe premise was intriguing, bu...\n"
     ]
    }
   ],
   "source": [
    "print(\"positive reviews \\t : \\t negative reviews\\n\")\n",
    "pretty_print_positive_and_negative(0)\n",
    "pretty_print_positive_and_negative(250)\n",
    "pretty_print_positive_and_negative(500)\n",
    "pretty_print_positive_and_negative(750)\n",
    "pretty_print_positive_and_negative(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three Counter objects to store positive, negative and total counts\n",
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all the words in all the reviews and increment the counts in the appropriate counter objects\n",
    "for i in range(len(positive_strings)):\n",
    "    for word in positive_strings[i].split(\" \"):\n",
    "        positive_counts[word] += 1\n",
    "        total_counts[word] += 1\n",
    "for i in range(len(negative_strings)):\n",
    "    for word in negative_strings[i].split(\" \"):\n",
    "        negative_counts[word] += 1\n",
    "        total_counts[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 11793),\n",
       " ('and', 6690),\n",
       " ('a', 6455),\n",
       " ('of', 6028),\n",
       " ('to', 5149),\n",
       " ('is', 4456),\n",
       " ('in', 3690),\n",
       " ('I', 2697),\n",
       " ('that', 2463),\n",
       " ('it', 2160),\n",
       " ('', 2142),\n",
       " ('this', 2062),\n",
       " ('as', 1843),\n",
       " ('with', 1814),\n",
       " ('for', 1718),\n",
       " ('was', 1682),\n",
       " ('The', 1653),\n",
       " ('his', 1301),\n",
       " ('but', 1300),\n",
       " ('film', 1219),\n",
       " ('are', 1210),\n",
       " ('on', 1172),\n",
       " ('movie', 1076),\n",
       " ('not', 1034),\n",
       " ('you', 1030),\n",
       " ('be', 955),\n",
       " ('have', 932),\n",
       " ('he', 902),\n",
       " ('by', 893),\n",
       " ('an', 868),\n",
       " ('one', 835),\n",
       " ('from', 813),\n",
       " ('at', 813),\n",
       " ('who', 812),\n",
       " ('has', 747),\n",
       " ('all', 732),\n",
       " ('her', 730),\n",
       " ('like', 667),\n",
       " ('about', 629),\n",
       " ('very', 605),\n",
       " ('This', 600),\n",
       " ('they', 587),\n",
       " ('so', 576),\n",
       " ('more', 553),\n",
       " ('good', 532),\n",
       " ('out', 530),\n",
       " ('or', 526),\n",
       " ('some', 524),\n",
       " ('just', 517),\n",
       " ('their', 493),\n",
       " ('It', 481),\n",
       " ('what', 480),\n",
       " ('which', 439),\n",
       " (\"it's\", 432),\n",
       " ('will', 425),\n",
       " ('when', 416),\n",
       " ('great', 415),\n",
       " ('can', 413),\n",
       " ('see', 411),\n",
       " ('up', 410),\n",
       " ('she', 408),\n",
       " ('really', 405),\n",
       " ('would', 400),\n",
       " ('than', 394),\n",
       " ('only', 394),\n",
       " ('had', 391),\n",
       " ('my', 381),\n",
       " ('story', 375),\n",
       " ('if', 373),\n",
       " ('its', 364),\n",
       " ('were', 360),\n",
       " ('also', 357),\n",
       " ('even', 352),\n",
       " ('into', 343),\n",
       " ('-', 339),\n",
       " ('get', 336),\n",
       " ('most', 329),\n",
       " ('been', 316),\n",
       " ('first', 316),\n",
       " ('well', 315),\n",
       " ('there', 315),\n",
       " ('other', 311),\n",
       " ('people', 311),\n",
       " ('much', 308),\n",
       " ('how', 306),\n",
       " ('we', 300),\n",
       " ('because', 298),\n",
       " ('him', 292),\n",
       " ('me', 289),\n",
       " ('time', 289),\n",
       " ('where', 288),\n",
       " ('!', 287),\n",
       " ('no', 283),\n",
       " ('best', 271),\n",
       " ('two', 271),\n",
       " ('do', 262),\n",
       " ('love', 259),\n",
       " ('And', 258),\n",
       " ('after', 249),\n",
       " ('think', 248)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_counts.most_common()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 10631),\n",
       " ('a', 5979),\n",
       " ('and', 5438),\n",
       " ('to', 5399),\n",
       " ('of', 5186),\n",
       " ('is', 3823),\n",
       " ('in', 3128),\n",
       " ('I', 3047),\n",
       " ('that', 2631),\n",
       " ('this', 2514),\n",
       " ('', 2427),\n",
       " ('it', 2270),\n",
       " ('was', 2109),\n",
       " ('The', 1660),\n",
       " ('for', 1624),\n",
       " ('with', 1517),\n",
       " ('as', 1476),\n",
       " ('movie', 1438),\n",
       " ('but', 1369),\n",
       " ('on', 1276),\n",
       " ('have', 1168),\n",
       " ('be', 1095),\n",
       " ('are', 1081),\n",
       " ('not', 1057),\n",
       " ('film', 979),\n",
       " ('you', 944),\n",
       " ('at', 921),\n",
       " ('his', 898),\n",
       " ('an', 826),\n",
       " ('one', 822),\n",
       " ('by', 807),\n",
       " ('just', 806),\n",
       " ('like', 795),\n",
       " ('they', 780),\n",
       " ('he', 754),\n",
       " ('or', 746),\n",
       " ('from', 711),\n",
       " ('all', 696),\n",
       " ('so', 679),\n",
       " ('who', 674),\n",
       " ('about', 660),\n",
       " ('out', 621),\n",
       " ('some', 597),\n",
       " ('has', 591),\n",
       " ('This', 577),\n",
       " ('would', 546),\n",
       " ('even', 528),\n",
       " ('only', 517),\n",
       " ('her', 508),\n",
       " ('more', 506),\n",
       " ('no', 505),\n",
       " ('if', 501),\n",
       " ('had', 472),\n",
       " ('It', 471),\n",
       " ('were', 466),\n",
       " ('when', 458),\n",
       " ('what', 456),\n",
       " ('really', 448),\n",
       " ('up', 445),\n",
       " ('there', 444),\n",
       " ('very', 443),\n",
       " (\"it's\", 425),\n",
       " ('can', 424),\n",
       " ('than', 421),\n",
       " ('good', 408),\n",
       " ('bad', 406),\n",
       " ('which', 404),\n",
       " ('into', 401),\n",
       " ('my', 398),\n",
       " ('been', 392),\n",
       " ('see', 384),\n",
       " ('she', 374),\n",
       " ('their', 372),\n",
       " ('-', 372),\n",
       " ('get', 371),\n",
       " ('much', 369),\n",
       " ('make', 356),\n",
       " ('because', 353),\n",
       " ('do', 347),\n",
       " ('any', 345),\n",
       " ('could', 330),\n",
       " ('me', 326),\n",
       " ('made', 324),\n",
       " (\"don't\", 315),\n",
       " ('we', 315),\n",
       " ('time', 303),\n",
       " ('other', 294),\n",
       " ('how', 293),\n",
       " ('people', 286),\n",
       " ('then', 270),\n",
       " ('movie.', 267),\n",
       " ('it.', 267),\n",
       " ('story', 262),\n",
       " ('first', 261),\n",
       " ('will', 260),\n",
       " ('its', 260),\n",
       " ('And', 259),\n",
       " ('too', 256),\n",
       " ('never', 256),\n",
       " ('being', 251)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_counts.most_common()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34325\n",
      "32292\n",
      "53557\n",
      "34325\n",
      "32292\n",
      "53557\n"
     ]
    }
   ],
   "source": [
    "print(len(positive_counts.items()))\n",
    "print(len(negative_counts.items()))\n",
    "print(len(total_counts.items()))\n",
    "print(len(positive_counts.most_common()))\n",
    "print(len(negative_counts.most_common()))\n",
    "print(len(total_counts.most_common()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_ratios = Counter()\n",
    "\n",
    "# Calculate the ratios of positive and negative uses of the most common words\n",
    "# Consider words to be \"common\" if they've been used at least 100 times\n",
    "for term, count in list(total_counts.most_common()):\n",
    "    if(count > 100):\n",
    "        pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "        pos_neg_ratios[term] = pos_neg_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos-to-neg ratio for 'the' = 1.1091986455981941\n",
      "Pos-to-neg ratio for 'amazing' = 0\n",
      "Pos-to-neg ratio for 'terrible' = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
    "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
    "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ratios to logs\n",
    "for word in pos_neg_ratios:\n",
    "    pos_neg_ratios[word] = np.log(pos_neg_ratios[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos-to-neg ratio for 'the' = 0.10363781369688876\n",
      "Pos-to-neg ratio for 'amazing' = 0\n",
      "Pos-to-neg ratio for 'terrible' = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
    "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
    "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 2.363645349755292),\n",
       " ('excellent', 1.4469189829363254),\n",
       " ('beautiful', 1.3862943611198906),\n",
       " ('great', 1.1010248350734937),\n",
       " ('definitely', 1.0271533246859648),\n",
       " ('His', 0.9985288301111273),\n",
       " ('liked', 0.9808292530117262),\n",
       " ('enjoy', 0.9227216222044455),\n",
       " ('world', 0.9118363815247748),\n",
       " ('best', 0.8747310021673603),\n",
       " ('well', 0.7689660171172966),\n",
       " ('own', 0.7381708619339005),\n",
       " ('young', 0.7359671777428735),\n",
       " ('role', 0.6931471805599453),\n",
       " ('gives', 0.6931471805599453),\n",
       " ('job', 0.6811709895132296),\n",
       " ('life', 0.6714071939235394),\n",
       " ('love', 0.666478933477784),\n",
       " ('true', 0.6384887680220812),\n",
       " ('John', 0.620387826277517),\n",
       " ('plays', 0.6176396280518002),\n",
       " ('still', 0.6115485366770659),\n",
       " ('different', 0.6074917359814515),\n",
       " ('She', 0.6017974019717174),\n",
       " ('small', 0.581921545449721),\n",
       " ('especially', 0.5717863235556778),\n",
       " ('year', 0.5658077581833438),\n",
       " ('each', 0.5280674302004967),\n",
       " ('New', 0.5212969236332861),\n",
       " ('performance', 0.5012561727498399),\n",
       " ('Hollywood', 0.49643688631389105),\n",
       " ('fun', 0.4936578201436253),\n",
       " ('man', 0.49308679942860906),\n",
       " ('will', 0.4875687616017234),\n",
       " ('--', 0.4813031844996689),\n",
       " ('quite', 0.47692407209030935),\n",
       " ('came', 0.4670230011075978),\n",
       " ('help', 0.4643056081310978),\n",
       " ('show', 0.4599532933922342),\n",
       " ('nice', 0.44320543609101143),\n",
       " ('always', 0.44031183943833246),\n",
       " ('may', 0.4289956055183586),\n",
       " ('also', 0.4224146664219376),\n",
       " ('between', 0.4206399061273995),\n",
       " (\"she's\", 0.4135623183407838),\n",
       " ('shows', 0.4054651081081644),\n",
       " ('He', 0.4029173360293657),\n",
       " ('us', 0.3948829987776274),\n",
       " ('recommend', 0.3899609215721992),\n",
       " ('feel', 0.38193461069797024),\n",
       " ('truly', 0.3794896217049037),\n",
       " ('bit', 0.3788980807234426),\n",
       " ('himself', 0.3746934494414107),\n",
       " ('played', 0.371563556432483),\n",
       " ('now', 0.371563556432483),\n",
       " ('his', 0.369605444040885),\n",
       " ('become', 0.3693601034660482),\n",
       " ('both', 0.3610133455373305),\n",
       " ('her', 0.3605965175919141),\n",
       " ('seeing', 0.36000273403140703),\n",
       " ('story', 0.35477199379264635),\n",
       " ('work', 0.3378718169756361),\n",
       " ('where', 0.3350843113463649),\n",
       " ('its', 0.3326334603140472),\n",
       " ('our', 0.329753286372468),\n",
       " ('DVD', 0.31709595765807425),\n",
       " ('again', 0.31666960932503324),\n",
       " ('series', 0.3136575588550416),\n",
       " ('three', 0.3136575588550416),\n",
       " ('When', 0.3109389346160482),\n",
       " ('him', 0.31077778724643024),\n",
       " ('very', 0.3094038955986167),\n",
       " ('watched', 0.30782663854424835),\n",
       " ('goes', 0.3028109540480811),\n",
       " ('place', 0.30147539458411676),\n",
       " ('takes', 0.29849298855599654),\n",
       " ('once', 0.2972515234679317),\n",
       " ('years', 0.2899522209863201),\n",
       " ('found', 0.284931039079891),\n",
       " ('although', 0.28223246768421617),\n",
       " ('their', 0.27893075439887455),\n",
       " ('during', 0.2772107725844855),\n",
       " ('men', 0.27625337662815813),\n",
       " ('most', 0.2745968329031255),\n",
       " ('family', 0.26495382137422485),\n",
       " ('good', 0.26292833329884263),\n",
       " ('real', 0.25714534859169924),\n",
       " ('play', 0.25642952894767657),\n",
       " ('two', 0.2550112901622323),\n",
       " ('given', 0.24946085963158324),\n",
       " ('everything', 0.2436220826577505),\n",
       " ('new', 0.23747337686903464),\n",
       " ('has', 0.23255855024881164),\n",
       " ('One', 0.23090555664969903),\n",
       " ('based', 0.2273898421956608),\n",
       " ('against', 0.22677331936478853),\n",
       " ('as', 0.22138167513844342),\n",
       " ('becomes', 0.21936282847430366),\n",
       " ('film', 0.21823355781665385),\n",
       " ('remember', 0.21570857282669165)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words most frequently seen in a review with a \"POSITIVE\" label\n",
    "pos_neg_ratios.most_common()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(total_counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53557\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "positive_labels = []\n",
    "for i in range(len(positive_tokenized)):\n",
    "    positive_labels.append('POSITIVE')\n",
    "negative_labels = []\n",
    "for i in range(len(negative_tokenized)):\n",
    "    negative_labels.append('NEGATIVE')\n",
    "    \n",
    "reviews = positive_tokenized + negative_tokenized\n",
    "labels = positive_labels + negative_labels\n",
    "reviews_and_labels = list(zip(reviews, labels))\n",
    "random.shuffle(reviews_and_labels)\n",
    "reviews, labels = zip(*reviews_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Encapsulate our neural network in a class\n",
    "class SentimentNetwork:\n",
    "    ## added min_count and polarity_cutoff parameters\n",
    "    def __init__(self, reviews, labels, min_count = 10,polarity_cutoff = 0.1,hidden_nodes = 10, learning_rate = 0.1):\n",
    "        \"\"\"Create a SentimenNetwork with the given settings\n",
    "        Args:\n",
    "            reviews(list) - List of reviews used for training\n",
    "            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews\n",
    "            min_count(int) - Words should only be added to the vocabulary \n",
    "                             if they occur more than this many times\n",
    "            polarity_cutoff(float) - The absolute value of a word's positive-to-negative\n",
    "                                     ratio must be at least this big to be considered.\n",
    "            hidden_nodes(int) - Number of nodes to create in the hidden layer\n",
    "            learning_rate(float) - Learning rate to use while training\n",
    "        \n",
    "        \"\"\"\n",
    "        # Assign a seed to our random number generator to ensure we get\n",
    "        # reproducable results during development \n",
    "        np.random.seed(1)\n",
    "\n",
    "        # process the reviews and their associated labels so that everything\n",
    "        # is ready for training\n",
    "        ## added min_count and polarity_cutoff arguments to pre_process_data call\n",
    "        self.pre_process_data(reviews, labels, polarity_cutoff, min_count)\n",
    "        \n",
    "        # Build the network to have the number of hidden nodes and the learning rate that\n",
    "        # were passed into this initializer. Make the same number of input nodes as\n",
    "        # there are vocabulary words and create a single output node.\n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "\n",
    "    ## added min_count and polarity_cutoff parameters\n",
    "    def pre_process_data(self, reviews, labels, polarity_cutoff, min_count):\n",
    "        \n",
    "        ## Calculate positive-to-negative ratios for words before building vocabulary\n",
    "        positive_counts = Counter()\n",
    "        negative_counts = Counter()\n",
    "        total_counts = Counter()\n",
    "\n",
    "        for i in range(len(reviews)):\n",
    "            if(labels[i] == 'POSITIVE'):\n",
    "                for word in reviews[i]:\n",
    "                    positive_counts[word] += 1\n",
    "                    total_counts[word] += 1\n",
    "            else:\n",
    "                for word in reviews[i]:\n",
    "                    negative_counts[word] += 1\n",
    "                    total_counts[word] += 1\n",
    "\n",
    "        pos_neg_ratios = Counter()\n",
    "\n",
    "        for term, count in list(total_counts.most_common()):\n",
    "            if(count >= 50):\n",
    "                pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "                pos_neg_ratios[term] = pos_neg_ratio\n",
    "\n",
    "        for word, ratio in pos_neg_ratios.most_common():\n",
    "            if(ratio > 1):\n",
    "                pos_neg_ratios[word] = np.log(ratio)\n",
    "            else:\n",
    "                pos_neg_ratios[word] = -np.log((1 / (ratio + 0.01)))\n",
    "\n",
    "        # populate review_vocab with all of the words in the given reviews\n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review:\n",
    "                ## only add words that occur at least min_count times\n",
    "                #                     and for words with pos/neg ratios, only add words\n",
    "                #                     that meet the polarity_cutoff\n",
    "                if(total_counts[word] > min_count):\n",
    "                    if(word in pos_neg_ratios.keys()):\n",
    "                        if((pos_neg_ratios[word] >= polarity_cutoff) or (pos_neg_ratios[word] <= -polarity_cutoff)):\n",
    "                            review_vocab.add(word)\n",
    "                    else:\n",
    "                        review_vocab.add(word)\n",
    "\n",
    "        # Convert the vocabulary set to a list so we can access words via indices\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        # populate label_vocab with all of the words in the given labels.\n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        # Convert the label vocabulary set to a list so we can access labels via indices\n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        # Store the sizes of the review and label vocabularies.\n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        # TODO This is already done earlier - can remove duplication\n",
    "        # Create a dictionary of words in the vocabulary mapped to index positions\n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        # Create a dictionary of labels mapped to index positions\n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "\n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Store the learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights\n",
    "\n",
    "        # These are the weights between the input layer and the hidden layer.\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "\n",
    "        # These are the weights between the hidden layer and the output layer.\n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        ## Removed self.layer_0; added self.layer_1\n",
    "        # The input layer, a two-dimensional matrix with shape 1 x hidden_nodes\n",
    "        self.layer_1 = np.zeros((1,hidden_nodes))\n",
    "    \n",
    "    ## Removed update_input_layer function\n",
    "    \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'POSITIVE'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    ## changed name of first parameter form 'training_reviews' \n",
    "    #                     to 'training_reviews_raw'\n",
    "    def train(self, training_reviews_raw, training_labels):\n",
    "\n",
    "        ## pre-process training reviews so we can deal \n",
    "        #                     directly with the indices of non-zero inputs\n",
    "        training_reviews = list()\n",
    "        for review in training_reviews_raw:\n",
    "            indices = set()\n",
    "            for word in review:\n",
    "                if(word in self.word2index.keys()):\n",
    "                    indices.add(self.word2index[word])\n",
    "            training_reviews.append(list(indices))\n",
    "\n",
    "        # make sure out we have a matching number of reviews and labels\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        # Keep track of correct predictions to display accuracy during training \n",
    "        correct_so_far = 0\n",
    "\n",
    "        # Remember when we started for printing time statistics\n",
    "        start = time.time()\n",
    "        \n",
    "        # loop through all the given reviews and run a forward and backward pass,\n",
    "        # updating weights for every item\n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            # Get the next review and its correct label\n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            ## Removed call to 'update_input_layer' function\n",
    "            #                     because 'layer_0' is no longer used\n",
    "\n",
    "            # Hidden layer\n",
    "            ## Add in only the weights for non-zero items\n",
    "            self.layer_1 *= 0\n",
    "            for index in review:\n",
    "                self.layer_1 += self.weights_0_1[index]\n",
    "\n",
    "            # Output layer\n",
    "            ## changed to use 'self.layer_1' instead of 'local layer_1'\n",
    "            layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))            \n",
    "            \n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # Update the weights\n",
    "            ## changed to use 'self.layer_1' instead of local 'layer_1'\n",
    "            self.weights_1_2 -= self.layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            \n",
    "            ## Only update the weights that were used in the forward pass\n",
    "            for index in review:\n",
    "                self.weights_0_1[index] -= layer_1_delta[0] * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            # Keep track of correct predictions.\n",
    "            if(layer_2 >= 0.5 and label == 'POSITIVE'):\n",
    "                correct_so_far += 1\n",
    "            elif(layer_2 < 0.5 and label == 'NEGATIVE'):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the training process. \n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
    "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \"\"\"\n",
    "        Attempts to predict the labels for the given testing_reviews,\n",
    "        and uses the test_labels to calculate the accuracy of those predictions.\n",
    "        \"\"\"\n",
    "        \n",
    "        # keep track of how many correct predictions we make\n",
    "        correct = 0\n",
    "\n",
    "        # we'll time how many predictions per second we make\n",
    "        start = time.time()\n",
    "\n",
    "        # Loop through each of the given reviews and call run to predict\n",
    "        # its label. \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the prediction process. \n",
    "\n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
    "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \"\"\"\n",
    "        Returns a POSITIVE or NEGATIVE prediction for the given review.\n",
    "        \"\"\"\n",
    "        # Run a forward pass through the network, like in the \"train\" function.\n",
    "        \n",
    "        ## Removed call to update_input_layer function\n",
    "        #                     because layer_0 is no longer used\n",
    "\n",
    "        # Hidden layer\n",
    "        ## Identify the indices used in the review and then add\n",
    "        #                     just those weights to layer_1 \n",
    "        self.layer_1 *= 0\n",
    "        unique_indices = set()\n",
    "        for word in review:\n",
    "            if word in self.word2index.keys():\n",
    "                unique_indices.add(self.word2index[word])\n",
    "        for index in unique_indices:\n",
    "            self.layer_1 += self.weights_0_1[index]\n",
    "        \n",
    "        # Output layer\n",
    "        ## changed to use self.layer_1 instead of local layer_1\n",
    "        layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "         \n",
    "        # Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;\n",
    "        # return NEGATIVE for other values\n",
    "        if(layer_2[0] >= 0.5):\n",
    "            return \"POSITIVE\"\n",
    "        else:\n",
    "            return \"NEGATIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "Progress:99.9% Speed(reviews/sec):2156. #Correct:733 #Trained:1000 Training Accuracy:73.3%"
     ]
    }
   ],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000],min_count=20,polarity_cutoff=0.05,learning_rate=0.01)\n",
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):2665. #Correct:771 #Tested:1000 Testing Accuracy:77.1%"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-1000:],labels[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "Progress:99.9% Speed(reviews/sec):3305. #Correct:782 #Trained:1000 Training Accuracy:78.2%"
     ]
    }
   ],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000],min_count=20,polarity_cutoff=0.8,learning_rate=0.01)\n",
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):4273. #Correct:782 #Tested:1000 Testing Accuracy:78.2%"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-1000:],labels[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "Progress:99.9% Speed(reviews/sec):1042. #Correct:710 #Trained:1000 Training Accuracy:71.0%"
     ]
    }
   ],
   "source": [
    "mlp_full = SentimentNetwork(reviews[:-1000],labels[:-1000],min_count=0,polarity_cutoff=0,learning_rate=0.01)\n",
    "mlp_full.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):5146. #Correct:782 #Tested:1000 Testing Accuracy:78.2%"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-1000:],labels[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar_words(focus = \"horrible\"):\n",
    "    most_similar = Counter()\n",
    "\n",
    "    for word in mlp_full.word2index.keys():\n",
    "        most_similar[word] = np.dot(mlp_full.weights_0_1[mlp_full.word2index[word]],mlp_full.weights_0_1[mlp_full.word2index[focus]])\n",
    "    \n",
    "    return most_similar.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.01794088658139491),\n",
       " ('love', 0.013920444609607658),\n",
       " ('beautiful', 0.011485460046508661),\n",
       " ('best', 0.009313694252545914),\n",
       " ('world', 0.009157208661895197),\n",
       " ('well', 0.008496713215832452),\n",
       " ('excellent', 0.008406002277286606),\n",
       " ('very', 0.008172055875934203),\n",
       " ('everyone', 0.007293758055630865),\n",
       " ('think', 0.007066441565353181)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_similar_words(\"excellent\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst', 0.010754856418980665),\n",
       " ('bad', 0.008711755262888135),\n",
       " ('waste', 0.0071232062821647265),\n",
       " ('no', 0.006903202996132405),\n",
       " ('?', 0.006470757216700413),\n",
       " ('awful', 0.006342002606895748),\n",
       " ('nothing', 0.006189831081304518),\n",
       " ('poor', 0.005867964223638356),\n",
       " ('had', 0.005205513402707153),\n",
       " ('instead', 0.0051714503635667776)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_similar_words(\"terrible\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.1.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.1.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "\n",
    "words_to_visualize = list()\n",
    "for word, ratio in pos_neg_ratios.most_common(500):\n",
    "    if(word in mlp_full.word2index.keys()):\n",
    "        words_to_visualize.append(word)\n",
    "    \n",
    "for word, ratio in list(reversed(pos_neg_ratios.most_common()))[0:500]:\n",
    "    if(word in mlp_full.word2index.keys()):\n",
    "        words_to_visualize.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "\n",
    "colors_list = list()\n",
    "vectors_list = list()\n",
    "for word in words_to_visualize:\n",
    "    if word in pos_neg_ratios.keys():\n",
    "        vectors_list.append(mlp_full.weights_0_1[mlp_full.word2index[word]])\n",
    "        if(pos_neg_ratios[word] > 0):\n",
    "            pos+=1\n",
    "            colors_list.append(\"#00ff00\")\n",
    "        else:\n",
    "            neg+=1\n",
    "            colors_list.append(\"#000000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "words_top_ted_tsne = tsne.fit_transform(vectors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"8ded27c0-9479-4d73-81b1-702e0bf34057\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"fbfa29eb-a002-4144-a10c-8ba6ed5b05c5\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"1018\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"1013\",\"type\":\"LinearAxis\"},{\"id\":\"1017\",\"type\":\"Grid\"},{\"id\":\"1018\",\"type\":\"LinearAxis\"},{\"id\":\"1022\",\"type\":\"Grid\"},{\"id\":\"1036\",\"type\":\"GlyphRenderer\"},{\"id\":\"1038\",\"type\":\"LabelSet\"}],\"title\":{\"id\":\"1002\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1027\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1005\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1009\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1007\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1011\",\"type\":\"LinearScale\"}},\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"PanTool\"},{\"attributes\":{\"source\":{\"id\":\"1032\",\"type\":\"ColumnDataSource\"}},\"id\":\"1037\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"SaveTool\"},{\"attributes\":{\"callback\":null,\"data\":{\"color\":[\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\"],\"names\":[\"!\",\"excellent\",\"beautiful\",\"great\",\"definitely\",\"His\",\"liked\",\"enjoy\",\"world\",\"best\",\"well\",\"own\",\"young\",\"role\",\"gives\",\"job\",\"life\",\"love\",\"true\",\"John\",\"plays\",\"still\",\"different\",\"She\",\"small\",\"especially\",\"year\",\"each\",\"New\",\"performance\",\"Hollywood\",\"fun\",\"man\",\"will\",\"--\",\"quite\",\"came\",\"help\",\"show\",\"nice\",\"always\",\"may\",\"also\",\"between\",\"shows\",\"He\",\"us\",\"recommend\",\"feel\",\"truly\",\"bit\",\"himself\",\"played\",\"now\",\"his\",\"become\",\"both\",\"her\",\"seeing\",\"story\",\"work\",\"where\",\"its\",\"our\",\"DVD\",\"again\",\"series\",\"three\",\"When\",\"him\",\"very\",\"watched\",\"goes\",\"place\",\"takes\",\"once\",\"years\",\"found\",\"although\",\"their\",\"during\",\"men\",\"most\",\"family\",\"good\",\"real\",\"play\",\"two\",\"given\",\"everything\",\"new\",\"has\",\"One\",\"based\",\"against\",\"as\",\"becomes\",\"film\",\"remember\",\"cast\",\"part\",\"many\",\"and\",\"actor\",\"later\",\"comedy\",\"lot\",\"As\",\"find\",\"does\",\"first\",\"day\",\"who\",\"times\",\"here\",\"am\",\"makes\",\"person\",\"with\",\"he\",\"since\",\"My\",\"You\",\"worth\",\"in\",\"things\",\"music\",\"after\",\"big\",\"fan\",\"hope\",\"is\",\"of\",\"In\",\"while\",\"though\",\"everyone\",\"films\",\"10\",\"While\",\"from\",\"several\",\"set\",\"understand\",\"character\",\"girl\",\"are\",\"A\",\"Of\",\"ending\",\"the\",\"version\",\"early\",\"by\",\"right\",\"full\",\"scenes\",\"woman\",\"more\",\"you\",\"she\",\"playing\",\"seen\",\"which\",\"people\",\"a\",\"need\",\"last\",\"see\",\"THE\",\"for\",\"other\",\"what\",\"all\",\"an\",\"little\",\"All\",\"how\",\"This\",\"down\",\"less\",\"TV\",\"few\",\"It\",\"rather\",\"home\",\"think\",\"saw\",\"i\",\"high\",\"one\",\"We\",\"main\",\"But\",\"old\",\"such\",\"look\",\".\",\"\\u0096\",\"The\",\"And\",\"way\",\"together\",\"use\",\"these\",\"mind\",\"not\",\"take\",\"audience\",\"can\",\"tell\",\"give\",\"probably\",\"comes\",\"until\",\"my\",\"long\",\"to\",\"almost\",\"about\",\"it\",\"time\",\"we\",\"but\",\"put\",\"course\",\"being\",\"know\",\"read\",\"that\",\"never\",\"better\",\"than\",\"They\",\"actors\",\"must\",\"actually\",\"keep\",\"up\",\"on\",\"shot\",\"rest\",\"them\",\"special\",\"-\",\"those\",\"when\",\"director\",\"get\",\"thought\",\"So\",\"really\",\"end\",\"sense\",\"every\",\"around\",\"American\",\"Some\",\"After\",\"come\",\"enough\",\"action\",\"I\",\"over\",\"me\",\"at\",\"seem\",\"back\",\"some\",\"did\",\"book\",\"scene\",\"be\",\"whole\",\"interesting\",\"far\",\"characters\",\"before\",\"away\",\"into\",\"out\",\"&\",\"so\",\"because\",\"without\",\"like\",\"much\",\"done\",\"fact\",\"watch\",\"had\",\"That\",\"doing\",\"For\",\"this\",\"funny\",\"second\",\"anyone\",\"At\",\"through\",\"having\",\"someone\",\"same\",\"been\",\"believe\",\"have\",\"was\",\"video\",\"another\",\"There\",\"ever\",\"watching\",\"absolutely\",\"couple\",\"entire\",\"your\",\"start\",\"something\",\"were\",\"go\",\"only\",\"kids\",\"should\",\"original\",\"too\",\"movies\",\"felt\",\"do\",\"then\",\"they\",\"screen\",\"movie\",\"if\",\"might\",\"left\",\"kind\",\"say\",\"hard\",\"would\",\"Just\",\"black\",\"could\",\"point\",\"Not\",\"To\",\"If\",\"let\",\"there\",\"sure\",\"or\",\"made\",\"want\",\"off\",\"got\",\"said\",\"else\",\"going\",\"pretty\",\"getting\",\"sort\",\"looking\",\"gets\",\"What\",\"even\",\"making\",\"seems\",\"anything\",\"just\",\"trying\",\"acting\",\"why\",\"try\",\"make\",\"reason\",\"idea\",\"maybe\",\"yet\",\"either\",\"effects\",\"used\",\"looks\",\"guy\",\"minutes\",\"went\",\"Even\",\"simply\",\"any\",\"no\",\"completely\",\"plot\",\"horror\",\"half\",\"thing\",\"mean\",\"totally\",\"script\",\"instead\",\"least\",\"nothing\",\"seemed\",\"2\",\"tries\",\"money\",\"bad\",\"poor\",\"worst\",\"waste\",\"waste\",\"worst\",\"poor\",\"bad\",\"money\",\"tries\",\"2\",\"seemed\",\"nothing\",\"least\",\"instead\",\"script\",\"totally\",\"mean\",\"thing\",\"half\",\"horror\",\"plot\",\"completely\",\"no\",\"any\",\"simply\",\"Even\",\"went\",\"minutes\",\"guy\",\"looks\",\"used\",\"effects\",\"either\",\"yet\",\"maybe\",\"idea\",\"reason\",\"make\",\"try\",\"why\",\"acting\",\"trying\",\"just\",\"anything\",\"seems\",\"making\",\"even\",\"What\",\"gets\",\"looking\",\"sort\",\"getting\",\"pretty\",\"going\",\"else\",\"said\",\"got\",\"off\",\"want\",\"made\",\"or\",\"sure\",\"there\",\"let\",\"If\",\"To\",\"Not\",\"point\",\"could\",\"black\",\"Just\",\"would\",\"hard\",\"say\",\"kind\",\"left\",\"might\",\"if\",\"movie\",\"screen\",\"they\",\"then\",\"do\",\"felt\",\"movies\",\"too\",\"original\",\"should\",\"kids\",\"only\",\"go\",\"were\",\"something\",\"start\",\"your\",\"entire\",\"couple\",\"absolutely\",\"watching\",\"ever\",\"There\",\"another\",\"video\",\"was\",\"have\",\"believe\",\"been\",\"same\",\"someone\",\"having\",\"through\",\"At\",\"anyone\",\"second\",\"funny\",\"this\",\"For\",\"doing\",\"That\",\"had\",\"watch\",\"fact\",\"done\",\"much\",\"like\",\"without\",\"because\",\"so\",\"&\",\"out\",\"into\",\"away\",\"before\",\"characters\",\"far\",\"interesting\",\"whole\",\"be\",\"scene\",\"book\",\"did\",\"some\",\"back\",\"seem\",\"at\",\"me\",\"over\",\"I\",\"action\",\"enough\",\"come\",\"After\",\"Some\",\"American\",\"around\",\"every\",\"sense\",\"end\",\"really\",\"So\",\"thought\",\"get\",\"director\",\"when\",\"those\",\"-\",\"special\",\"them\",\"rest\",\"shot\",\"on\",\"up\",\"keep\",\"actually\",\"must\",\"actors\",\"They\",\"than\",\"better\",\"never\",\"that\",\"read\",\"know\",\"being\",\"course\",\"put\",\"but\",\"we\",\"time\",\"it\",\"about\",\"almost\",\"to\",\"long\",\"my\",\"until\",\"comes\",\"probably\",\"give\",\"tell\",\"can\",\"audience\",\"take\",\"not\",\"mind\",\"these\",\"use\",\"together\",\"way\",\"And\",\"The\",\"\\u0096\",\".\",\"look\",\"such\",\"old\",\"But\",\"main\",\"We\",\"one\",\"high\",\"i\",\"saw\",\"think\",\"home\",\"rather\",\"It\",\"few\",\"TV\",\"less\",\"down\",\"This\",\"how\",\"All\",\"little\",\"an\",\"all\",\"what\",\"other\",\"for\",\"THE\",\"see\",\"last\",\"need\",\"a\",\"people\",\"which\",\"seen\",\"playing\",\"she\",\"you\",\"more\",\"woman\",\"scenes\",\"full\",\"right\",\"by\",\"early\",\"version\",\"the\",\"ending\",\"Of\",\"A\",\"are\",\"girl\",\"character\",\"understand\",\"set\",\"several\",\"from\",\"While\",\"10\",\"films\",\"everyone\",\"though\",\"while\",\"In\",\"of\",\"is\",\"hope\",\"fan\",\"big\",\"after\",\"music\",\"things\",\"in\",\"worth\",\"You\",\"My\",\"since\",\"he\",\"with\",\"person\",\"makes\",\"am\",\"here\",\"times\",\"who\",\"day\",\"first\",\"does\",\"find\",\"As\",\"lot\",\"comedy\",\"later\",\"actor\",\"and\",\"many\",\"part\",\"cast\",\"remember\",\"film\",\"becomes\",\"as\",\"against\",\"based\",\"One\",\"has\",\"new\",\"everything\",\"given\",\"two\",\"play\",\"real\",\"good\",\"family\",\"most\",\"men\",\"during\",\"their\",\"although\",\"found\",\"years\",\"once\",\"takes\",\"place\",\"goes\",\"watched\",\"very\",\"him\",\"When\",\"three\",\"series\",\"again\",\"DVD\",\"our\",\"its\",\"where\",\"work\",\"story\",\"seeing\",\"her\",\"both\",\"become\",\"his\",\"now\",\"played\",\"himself\",\"bit\",\"truly\",\"feel\",\"recommend\",\"us\",\"He\",\"shows\",\"between\",\"also\",\"may\",\"always\",\"nice\",\"show\",\"help\",\"came\",\"quite\",\"--\",\"will\",\"man\",\"fun\",\"Hollywood\",\"performance\",\"New\",\"each\",\"year\",\"especially\",\"small\",\"She\",\"different\",\"still\",\"plays\",\"John\",\"true\",\"love\",\"life\",\"job\",\"gives\",\"role\",\"young\",\"own\",\"well\",\"best\",\"world\",\"enjoy\",\"liked\",\"His\",\"definitely\",\"great\",\"beautiful\",\"excellent\",\"!\"],\"x1\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[814]},\"x2\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[814]}},\"selected\":{\"id\":\"1045\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1046\",\"type\":\"UnionRenderers\"}},\"id\":\"1032\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1023\",\"type\":\"PanTool\"},{\"id\":\"1024\",\"type\":\"WheelZoomTool\"},{\"id\":\"1025\",\"type\":\"ResetTool\"},{\"id\":\"1026\",\"type\":\"SaveTool\"}]},\"id\":\"1027\",\"type\":\"Toolbar\"},{\"attributes\":{\"plot\":null,\"text\":\"vector T-SNE for most polarized words\"},\"id\":\"1002\",\"type\":\"Title\"},{\"attributes\":{\"callback\":null},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{\"callback\":null},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{\"fill_color\":{\"field\":\"color\"},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1034\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{\"data_source\":{\"id\":\"1032\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1034\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1035\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"1037\",\"type\":\"CDSView\"}},\"id\":\"1036\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"formatter\":{\"id\":\"1043\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1014\",\"type\":\"BasicTicker\"}},\"id\":\"1013\",\"type\":\"LinearAxis\"},{\"attributes\":{\"plot\":{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1014\",\"type\":\"BasicTicker\"}},\"id\":\"1017\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1043\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1041\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1035\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"Selection\"},{\"attributes\":{\"formatter\":{\"id\":\"1041\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1019\",\"type\":\"BasicTicker\"}},\"id\":\"1018\",\"type\":\"LinearAxis\"},{\"attributes\":{\"plot\":{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"source\":{\"id\":\"1032\",\"type\":\"ColumnDataSource\"},\"text\":{\"field\":\"names\"},\"text_align\":\"center\",\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"},\"y_offset\":{\"value\":6}},\"id\":\"1038\",\"type\":\"LabelSet\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1019\",\"type\":\"BasicTicker\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1019\",\"type\":\"BasicTicker\"}},\"id\":\"1022\",\"type\":\"Grid\"}],\"root_ids\":[\"1003\"]},\"title\":\"Bokeh Application\",\"version\":\"1.0.1\"}};\n",
       "  var render_items = [{\"docid\":\"fbfa29eb-a002-4144-a10c-8ba6ed5b05c5\",\"roots\":{\"1003\":\"8ded27c0-9479-4d73-81b1-702e0bf34057\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1003"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"vector T-SNE for most polarized words\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=words_top_ted_tsne[:,0],\n",
    "                                    x2=words_top_ted_tsne[:,1],\n",
    "                                    names=words_to_visualize,\n",
    "                                    color=colors_list))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source, fill_color=\"color\")\n",
    "\n",
    "word_labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                  source=source, text_align='center')\n",
    "p.add_layout(word_labels)\n",
    "\n",
    "show(p)\n",
    "\n",
    "# green indicates positive words, black indicates negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
