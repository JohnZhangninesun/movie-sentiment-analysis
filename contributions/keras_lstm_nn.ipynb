{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "CML_IG6z-iwM",
    "outputId": "d9301f36-c1cf-4b3f-e639-a731880ed036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jeremie/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# uncomment these for Google collab, will have already been installed in local environment \n",
    "# if 'pip install -r requirements.txt' has been run\n",
    "#!pip install nltk\n",
    "#!pip install --upgrade gensim\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "\n",
    "\n",
    "import glob\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FJiWamI00hBp",
    "outputId": "e3c105d5-037f-4521-b8e1-a83cb7a5edeb"
   },
   "outputs": [],
   "source": [
    "# MacOSX: See https://www.mkyong.com/mac/wget-on-mac-os-x/ for wget\n",
    "if not os.path.isdir('../aclImdb'):\n",
    "    if not os.path.isfile('../aclImdb_v1.tar.gz'):\n",
    "      !wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz \n",
    "\n",
    "    if not os.path.isdir('../aclImdb'):  \n",
    "      !tar -xf aclImdb_v1.tar.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U5Tnmoh-Dpfk"
   },
   "outputs": [],
   "source": [
    "time_beginning_of_notebook = time.time()\n",
    "SAMPLE_SIZE=3000\n",
    "positive_sample_file_list = glob.glob(os.path.join('../aclImdb/train/pos', \"*.txt\"))\n",
    "positive_sample_file_list = positive_sample_file_list[:SAMPLE_SIZE]\n",
    "\n",
    "negative_sample_file_list = glob.glob(os.path.join('../aclImdb/train/neg', \"*.txt\"))\n",
    "negative_sample_file_list = negative_sample_file_list[:SAMPLE_SIZE]\n",
    "\n",
    "import re\n",
    "\n",
    "# load doc into memory\n",
    "# regex to clean markup elements \n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r', encoding='utf8')\n",
    "    # read all text\n",
    "    text = re.sub('<[^>]*>', ' ', file.read())\n",
    "    #text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "lfr3bXOgXNJJ",
    "outputId": "cc06dd0d-e886-4090-c972-cd05520adaf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive review(s): NYC model Alison Parker (Cristina Raines) rents a room in an old brownstone where she meets a few bi\n",
      "Negative review(s): The reason the DVD releases of this film are in black and white is because nobody can get their hand\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df_positives = pd.DataFrame({'reviews':[load_doc(x) for x in positive_sample_file_list], 'sentiment': np.ones(SAMPLE_SIZE)})\n",
    "df_negatives = pd.DataFrame({'reviews':[load_doc(x) for x in negative_sample_file_list], 'sentiment': np.zeros(SAMPLE_SIZE)})\n",
    "\n",
    "print(\"Positive review(s):\", df_positives['reviews'][1][:100])\n",
    "print(\"Negative review(s):\", df_negatives['reviews'][1][:100])\n",
    "\n",
    "df = pd.concat([df_positives, df_negatives], ignore_index=True)\n",
    "\n",
    "df = shuffle(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['reviews'], df['sentiment'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4500"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fjDcOMEUoToE"
   },
   "source": [
    "### LSTM with Keras (Sequential model)\n",
    "\n",
    "\n",
    "Please note that the below code is executed on GPU instances on Colab, this wont work on your local machine, use the flag to enable/disable running in CPU or GPU mode, set `run_in_GPU_mode_on_colab=false` in order to be able to run in CPU mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# def lstm_keras():\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# def lstm_keras():\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['reviews'], df['sentiment'], test_size=0.25)\n",
    "\n",
    "vocab_size = 1000\n",
    "\n",
    "# Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',\\\n",
    "#           lower=True, split=' ', char_level=False, oov_token=None, document_count=0)\n",
    "\n",
    "tokenize = Tokenizer(num_words=vocab_size)\n",
    "tokenize.fit_on_texts(X_train)\n",
    "\n",
    "encoded_X_train = tokenize.texts_to_sequences(X_train)\n",
    "encoded_X_test = tokenize.texts_to_sequences(X_test)\n",
    "\n",
    "encoded_X_train = sequence.pad_sequences(encoded_X_train, maxlen=vocab_size)\n",
    "encoded_X_test = sequence.pad_sequences(encoded_X_test, maxlen=vocab_size)\n",
    "\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y_train)\n",
    "encoded_y_train = encoder.transform(y_train)\n",
    "encoded_y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "fVN5C_34oSgO",
    "outputId": "03f65fd1-c9fb-47dc-8025-afa10d4f68d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 1000, 512)         512000    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               328192    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 840,321\n",
      "Trainable params: 840,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4050 samples, validate on 450 samples\n",
      "Epoch 1/3\n",
      "4050/4050 [==============================] - 137s 34ms/step - loss: 0.5934 - acc: 0.6746 - val_loss: 0.4947 - val_acc: 0.7889\n",
      "Epoch 2/3\n",
      "4050/4050 [==============================] - 141s 35ms/step - loss: 0.3752 - acc: 0.8385 - val_loss: 0.4827 - val_acc: 0.8200\n",
      "Epoch 3/3\n",
      "4050/4050 [==============================] - 149s 37ms/step - loss: 0.3271 - acc: 0.8647 - val_loss: 0.5219 - val_acc: 0.7489\n",
      "1500/1500 [==============================] - 16s 11ms/step\n",
      "Test score: 0.47664378261566165\n",
      "Test accuracy: 0.7753333328564962\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_features = 1000\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 512,input_length=vocab_size))\n",
    "model.add(LSTM(128))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "           optimizer='adam',\n",
    "           metrics=['accuracy'])\n",
    "\n",
    "batch_size=64\n",
    "epochs=3\n",
    "history = model.fit(encoded_X_train, encoded_y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=epochs, \n",
    "              verbose=1, \n",
    "              validation_split=0.1)\n",
    "\n",
    "score = model.evaluate(encoded_X_test, encoded_y_test, \n",
    "                     batch_size=batch_size, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fjDcOMEUoToE"
   },
   "source": [
    "### run with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lstm_keras():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['reviews'], df['sentiment'], test_size=0.25)\n",
    "\n",
    "    vocab_size = 1000\n",
    "\n",
    "    # Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',\\\n",
    "    #           lower=True, split=' ', char_level=False, oov_token=None, document_count=0)\n",
    "\n",
    "    tokenize = Tokenizer(num_words=vocab_size)\n",
    "    tokenize.fit_on_texts(X_train)\n",
    "\n",
    "    encoded_X_train = tokenize.texts_to_sequences(X_train)\n",
    "    encoded_X_test = tokenize.texts_to_sequences(X_test)\n",
    "\n",
    "    encoded_X_train = sequence.pad_sequences(encoded_X_train, maxlen=vocab_size)\n",
    "    encoded_X_test = sequence.pad_sequences(encoded_X_test, maxlen=vocab_size)\n",
    "\n",
    "\n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(y_train)\n",
    "    encoded_y_train = encoder.transform(y_train)\n",
    "    encoded_y_test = encoder.transform(y_test)\n",
    "\n",
    "\n",
    "\n",
    "    max_features = 1000\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 512,input_length=vocab_size))\n",
    "    model.add(LSTM(128))  # try using a GRU instead, for fun\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "    batch_size=64\n",
    "    epochs=3\n",
    "    history = model.fit(encoded_X_train, encoded_y_train, \n",
    "                  batch_size=batch_size, \n",
    "                  epochs=epochs, \n",
    "                  verbose=1, \n",
    "                  validation_split=0.1)\n",
    "\n",
    "    score = model.evaluate(encoded_X_test, encoded_y_test, \n",
    "                         batch_size=batch_size, verbose=1)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "run_in_GPU_mode_on_colab=False\n",
    "\n",
    "if run_in_GPU_mode_on_colab:  \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "\n",
    "    with tf.device('/gpu:0'):\n",
    "        session_gpu = tf.Session(config=config)\n",
    "        session_gpu.run(tf.global_variables_initializer())\n",
    "        session_gpu.run(tf.tables_initializer())\n",
    "        start = time.time()\n",
    "        session_gpu.run(lstm_keras())\n",
    "        end = time.time()\n",
    "        gpu_time = end - start\n",
    "        print('Duration on the GPU: {} seconds'.format(gpu_time))\n",
    "else:\n",
    "    start = time.time()\n",
    "    lstm_keras()\n",
    "    end = time.time()\n",
    "    cpu_time = end - start\n",
    "    print('Duration on the CPU: {} seconds'.format(cpu_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gvChJ9kdot4q"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment analysis of movies (IMDB).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
