{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A0XMzfB5_EtE"
   },
   "source": [
    "### Sentiment analysis of movie (IMDB) reviews using dataset provided by the ACL 2011 paper, see http://ai.stanford.edu/~amaas/data/sentiment/.\n",
    "\n",
    "#### Dataset can be downloaded separately from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz, but wont be necessary as the download process has been embedded in the notebook and source file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "CML_IG6z-iwM",
    "outputId": "ed907d98-b14f-42a8-c0a4-5b8a3082c9f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodolfo\\Anaconda3\\envs\\flasky\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# !pip install nltk\n",
    "# !pip install --upgrade gensim\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "#nltk.download('punkt')>>> import nltk\n",
    "\n",
    "\n",
    "import glob\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FJiWamI00hBp",
    "outputId": "177c454e-cf13-49a5-91dd-74c40c2365fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the MacOSX, you will need to install wget, see https://www.mkyong.com/mac/wget-on-mac-os-x/\n"
     ]
    }
   ],
   "source": [
    "# MacOSX: See https://www.mkyong.com/mac/wget-on-mac-os-x/ for wget\n",
    "print('On the MacOSX, you will need to install wget, see https://www.mkyong.com/mac/wget-on-mac-os-x/')\n",
    "\n",
    "if not os.path.isfile('aclImdb_v1.tar.gz'):\n",
    "  !wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz \n",
    "\n",
    "if not os.path.isfile('aclImdb'):  \n",
    "  !tar -xf aclImdb_v1.tar.gz \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U5Tnmoh-Dpfk"
   },
   "outputs": [],
   "source": [
    "time_beginning_of_notebook = time.time()\n",
    "SAMPLE_SIZE=1000\n",
    "positive_sample_file_list = glob.glob(os.path.join('aclImdb/train/pos', \"*.txt\"))\n",
    "positive_sample_file_list = positive_sample_file_list[:SAMPLE_SIZE]\n",
    "\n",
    "negative_sample_file_list = glob.glob(os.path.join('aclImdb/train/neg', \"*.txt\"))\n",
    "negative_sample_file_list = negative_sample_file_list[:SAMPLE_SIZE]\n",
    "\n",
    "import re\n",
    "\n",
    "# load doc into memory\n",
    "# regex to clean markup elements \n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r', encoding='utf8')\n",
    "    # read all text\n",
    "    text = re.sub('<[^>]*>', ' ', file.read())\n",
    "    #text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vMYBkcdIB9uc"
   },
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "cz5eJi7AGSqR",
    "outputId": "854b06de-6285-44bb-8f53-49f32565c770"
   },
   "outputs": [],
   "source": [
    "positive_strings = [load_doc(x) for x in positive_sample_file_list]\n",
    "#print('\\n Positive reviews \\n ',positive_strings[:5])\n",
    "\n",
    "negative_strings = [load_doc(x) for x in negative_sample_file_list]\n",
    "#print('\\n Negative reviews \\n ', negative_strings[:5])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "C0WiHTr7I4CN",
    "outputId": "238e7430-78f7-46b1-9a21-c00abac09d56"
   },
   "outputs": [],
   "source": [
    "positive_tokenized = [word_tokenize(s) for s in positive_strings]\n",
    "#print('\\n Positive tokenized 1 \\n {} \\n\\n Positive tokenized 2 \\n {}'. format(positive_tokenized[1], positive_tokenized[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "YDP-eqAGIq5R",
    "outputId": "6e254ed0-15ae-420b-d9d5-0340d73a9de2"
   },
   "outputs": [],
   "source": [
    "negative_tokenized = [word_tokenize(s) for s in negative_strings]\n",
    "#print('\\n Negative tokenized 1 \\n {} \\n\\n  Negative tokenized 2 \\n {}'. format(negative_tokenized[1], negative_tokenized[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6bgN1KJRMPpq",
    "outputId": "9ebc93dd-a3d4-45f2-f8c0-e4ba957c8ce7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count across all reviews (before stripping tokens): 255821\n",
      "Non alphanumeric characters found in universe vocabulary {'?', '=', '}', '-', '(', '[', ';', ')', ']', \"'\", '!', ':'}\n",
      "Word count across all reviews (after stripping tokens): 221986\n"
     ]
    }
   ],
   "source": [
    "# load doc into memory\n",
    "with open('aclImdb/imdb.vocab', encoding='utf8') as f:\n",
    "    #content = f.readlines()\n",
    "    universe_vocabulary = [x.strip() for x in f.readlines()]\n",
    "\n",
    "print(\"Word count across all reviews (before stripping tokens):\", sum([len(token) for token in positive_tokenized]))\n",
    "\n",
    "#Checking the not alphanumeric characters in vocabulary\n",
    "non_alphanumeric_set = set()\n",
    "for word in universe_vocabulary:\n",
    "    non_alphanumeric_set |= set(re.findall('\\W', word))\n",
    "print('Non alphanumeric characters found in universe vocabulary', non_alphanumeric_set)\n",
    "\n",
    "\n",
    "stripped_positive_tokenized = []\n",
    "for tokens in positive_tokenized:\n",
    "  stripped_positive_tokenized.append([token.lower() for token in tokens if token.lower() in universe_vocabulary])\n",
    "\n",
    "print(\"Word count across all reviews (after stripping tokens):\", sum([len(token) for token in stripped_positive_tokenized]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "DSFWrZInMueS",
    "outputId": "56c46895-8165-416e-eebe-099aeb9b719e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count across all reviews (before stripping tokens): 255821\n",
      "Word count across all reviews (after stripping tokens): 217639\n"
     ]
    }
   ],
   "source": [
    "print(\"Word count across all reviews (before stripping tokens):\", sum([len(token) for token in positive_tokenized]))\n",
    "stripped_negative_tokenized = []\n",
    "for tokens in negative_tokenized:\n",
    "  stripped_negative_tokenized.append([token.lower() for token in tokens if token.lower() in universe_vocabulary])\n",
    "\n",
    "print(\"Word count across all reviews (after stripping tokens):\", sum([len(token) for token in stripped_negative_tokenized]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnu21deYOkDE"
   },
   "source": [
    "## Modelling \n",
    "\n",
    "We have decided to do the use the below models and vectorisation techniques to test our their accuracy / score, the idea is to use a one model and one vectorization technique and plot a score.\n",
    "\n",
    "**Simple models**\n",
    "\n",
    "- Logistic Regression\n",
    "- Random Forst\n",
    "- LSTM\n",
    "- GRU\n",
    "- CNN\n",
    "\n",
    "**Vectorisation techniques**\n",
    "- Bag of Words\n",
    "- Word2Vec\n",
    "- TFIDF (probability scores)\n",
    "- FastText\n",
    "- Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression.\n",
    "## Introducing Pipeline: http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "## Introducing TfdfVectorizer: http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "## Introducing cross_val_score http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df_positives = pd.DataFrame({'reviews':[load_doc(x) for x in positive_sample_file_list], 'sentiment': np.ones(SAMPLE_SIZE)})\n",
    "df_negatives = pd.DataFrame({'reviews':[load_doc(x) for x in negative_sample_file_list], 'sentiment': np.zeros(SAMPLE_SIZE)})\n",
    "\n",
    "df = pd.concat([df_positives, df_negatives], ignore_index=True)\n",
    "\n",
    "df = shuffle(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['reviews'], df['sentiment'], test_size=0.25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regress model using Bag of Words vectorisation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 1.0\n",
      "Test accuracy 0.858\n",
      "Train accuracy list [0.86092715 0.86754967 0.87417219 0.83333333 0.83333333 0.82666667\n",
      " 0.87333333 0.83892617 0.8590604  0.91946309] \n",
      "Train accuracy mean 0.8586765337718714 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "CountVec = CountVectorizer()\n",
    "lr_CV = Pipeline([('vect', CountVec), ('clf', LogisticRegression(random_state=0))])\n",
    "lr_CV.fit(X_train, y_train)\n",
    "print('Train accuracy {}'.format(lr_CV.score(X_train, y_train)))\n",
    "print('Test accuracy {}'.format(lr_CV.score(X_test, y_test)))\n",
    "\n",
    "# # Trying with cross_val_score\n",
    "lr = LogisticRegression()\n",
    "k_folds = 10\n",
    "X_train_CV = CountVec.fit_transform(X_train)\n",
    "type(X_train_CV)\n",
    "print('Train accuracy list {} '.format(cross_val_score(lr, X_train_CV, y_train, cv= k_folds))) \n",
    "print('Train accuracy mean {} '.format(cross_val_score(lr, X_train_CV, y_train, cv= k_folds).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regress model using TfidfVectorizer vectorisation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.982\n",
      "Test accuracy 0.88\n",
      "Train accuracy list [0.89403974 0.89403974 0.86754967 0.88666667 0.85333333 0.83333333\n",
      " 0.89333333 0.86577181 0.89261745 0.89932886] \n",
      "Train accuracy mean 0.8780013926544884 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', tfidf), ('clf', LogisticRegression(random_state=0))])\n",
    "lr_tfidf.fit(X_train, y_train)\n",
    "print('Train accuracy {}'.format(lr_tfidf.score(X_train, y_train)))\n",
    "print('Test accuracy {}'.format(lr_tfidf.score(X_test, y_test)))\n",
    "\n",
    "# Trying with cross_val_score\n",
    "lr = LogisticRegression()\n",
    "k_folds = 10\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "print('Train accuracy list {} '.format(cross_val_score(lr, X_train_tfidf, y_train, cv= k_folds))) \n",
    "print('Train accuracy mean {} '.format(cross_val_score(lr, X_train_tfidf, y_train, cv= k_folds).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regress model using TfidfVectorizer and different values for C hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_value 1.0 Test Score 0.88 Train_score 0.982\n",
      "C_value 1.1 Test Score 0.886 Train_score 0.9853333333333333\n",
      "C_value 1.2000000000000002 Test Score 0.886 Train_score 0.9866666666666667\n",
      "C_value 1.3000000000000003 Test Score 0.886 Train_score 0.9873333333333333\n",
      "C_value 1.4000000000000004 Test Score 0.886 Train_score 0.9886666666666667\n",
      "C_value 1.5000000000000004 Test Score 0.886 Train_score 0.9886666666666667\n",
      "C_value 1.6000000000000005 Test Score 0.888 Train_score 0.9893333333333333\n",
      "C_value 1.7000000000000006 Test Score 0.888 Train_score 0.99\n",
      "C_value 1.8000000000000007 Test Score 0.888 Train_score 0.99\n",
      "C_value 1.9000000000000008 Test Score 0.89 Train_score 0.99\n"
     ]
    }
   ],
   "source": [
    "C_values = np.arange(1,2,0.1)\n",
    "results = []\n",
    "\n",
    "for value in C_values:   \n",
    "    lr_tfidf = Pipeline([('vect', tfidf), ('clf', LogisticRegression(random_state=0, C=value))])\n",
    "    lr_tfidf.fit(X_train, y_train)\n",
    "    train_score = lr_tfidf.score(X_train, y_train)\n",
    "    score = lr_tfidf.score(X_test, y_test)\n",
    "    print('C_value {} Test Score {} Train_score {}'.format(value, score, train_score))\n",
    "    results.append(score)\n",
    "\n",
    "time_end_of_notebook = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "colab_type": "code",
    "id": "6siRLHQU79F7",
    "outputId": "64142e5a-67d5-408b-e067-45f2551d0d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 1000\n",
      "Full notebook execution duration: 1743.947651386261 seconds\n",
      "Full notebook execution duration: 29.065794189771015 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Vectorisation techniques</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Bag of Words</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>Pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Models Vectorisation techniques    Score\n",
       "0  Logistic Regression             Bag of Words     0.89\n",
       "1  Logistic Regression                 Word2Vec  Pending\n",
       "2  Logistic Regression                    TFIDF     0.99"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "table_models_vectorization = pd.DataFrame(\n",
    "     {'Models':                   [\"Logistic Regression\", \"Logistic Regression\", \"Logistic Regression\"], \n",
    "      'Vectorisation techniques': [\"Bag of Words\",        \"Word2Vec\", \"TFIDF\"], \n",
    "      'Score':                    [score,                 \"Pending\", lr_tfidf.score(X_train, y_train) ]},\n",
    "    columns=['Models','Vectorisation techniques','Score']\n",
    ")\n",
    "print(\"Sample size:\", SAMPLE_SIZE)\n",
    "\n",
    "duration = time_end_of_notebook - time_beginning_of_notebook\n",
    "\n",
    "print(\"Full notebook execution duration:\", duration, \"seconds\")\n",
    "print(\"Full notebook execution duration:\", duration / 60, \"minutes\")\n",
    "\n",
    "table_models_vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment analysis of movies (IMDB).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
