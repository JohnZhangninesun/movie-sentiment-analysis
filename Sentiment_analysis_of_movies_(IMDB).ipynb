{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment analysis of movies (IMDB).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "A0XMzfB5_EtE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sentiment analysis of movie (IMDB) reviews using dataset provided by the ACL 2011 paper, see http://ai.stanford.edu/~amaas/data/sentiment/.\n",
        "\n",
        "#### Dataset can be downloaded separately from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz, but wont be necessary as the download process has been embedded in the notebook and source file."
      ]
    },
    {
      "metadata": {
        "id": "CML_IG6z-iwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "de9c96e7-36a6-4ca4-a81d-0d0f47ebcbaf"
      },
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install --upgrade gensim\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import glob\n",
        "from gensim.models import Word2Vec  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.11.0)\n",
            "Requirement already up-to-date: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
            "Requirement already satisfied, skipping upgrade: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.20)\n",
            "Requirement already satisfied, skipping upgrade: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.8.24)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.20 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.20)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.20->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.20->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FJiWamI00hBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "f3137dc9-d232-4759-815b-c61e744cbbac"
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isfile('aclImdb_v1.tar.gz'):\n",
        "  !wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz \n",
        "\n",
        "if not os.path.isfile('aclImdb'):  \n",
        "  !tar -xf aclImdb_v1.tar.gz \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-10 21:14:16--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  71.8MB/s    in 1.1s    \n",
            "\n",
            "2018-10-10 21:14:17 (71.8 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U5Tnmoh-Dpfk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SAMPLE_SIZE=600\n",
        "positive_sample_file_list = glob.glob(os.path.join('aclImdb/train/pos', \"*.txt\"))\n",
        "positive_sample_file_list = positive_sample_file_list[:SAMPLE_SIZE]\n",
        "\n",
        "negative_sample_file_list = glob.glob(os.path.join('aclImdb/train/neg', \"*.txt\"))\n",
        "negative_sample_file_list = negative_sample_file_list[:SAMPLE_SIZE]\n",
        "\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cz5eJi7AGSqR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pos_strings = [load_doc(x) for x in positive_sample_file_list]\n",
        "print(pos_strings[:10])\n",
        "\n",
        "neg_strings = [load_doc(x) for x in negative_sample_file_list]\n",
        "print(neg_strings[:10])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ln1-QrMcGOgD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pos_labels = np.array(SAMPLE_SIZE * [[1,0]])\n",
        "pos_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pS4Rhx54IoW9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "neg_labels = np.array(SAMPLE_SIZE * [[0,1]])\n",
        "neg_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C0WiHTr7I4CN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pos_tokenized = [word_tokenize(s) for s in pos_strings]\n",
        "print(pos_tokenized[1])\n",
        "print(pos_tokenized[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YDP-eqAGIq5R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "neg_tokenized = [word_tokenize(s) for s in neg_strings]\n",
        "print(neg_tokenized[1])\n",
        "print(neg_tokenized[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6bgN1KJRMPpq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load doc into memory\n",
        "with open('aclImdb/imdb.vocab') as f:\n",
        "  content = f.readlines()\n",
        "universe_vocabulary = [x.strip() for x in content]\n",
        "\n",
        "print(len(universe_vocabulary))\n",
        "print(len(set(universe_vocabulary)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bpggN67wRqI3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_ted = Word2Vec(sentences=pos_tokenized, size=100, window=5, min_count=5, workers=1, sg=0, seed=42)\n",
        "model_ted.wv.most_similar(\"brother\")\n",
        "\n",
        "print(np.linalg.norm(model_ted.wv['man'] - model_ted.wv['woman']))\n",
        "print(np.linalg.norm(model_ted.wv['father'] - model_ted.wv['mother']))\n",
        "print(np.linalg.norm(model_ted.wv['brother'] - model_ted.wv['sister']))\n",
        "print(np.linalg.norm(model_ted.wv['house'] - model_ted.wv['ship']))\n",
        "\n",
        "print(np.linalg.norm(model_ted.wv['father'] - model_ted.wv['mother']))\n",
        "print(np.linalg.norm(model_ted.wv['sister'] - model_ted.wv['mother']))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}